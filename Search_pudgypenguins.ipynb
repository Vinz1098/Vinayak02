{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vinz1098/Vinayak02/blob/main/Search_pudgypenguins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-api-python-client pandas\n"
      ],
      "metadata": {
        "id": "aAxjYZ2UCBOQ",
        "outputId": "22fd2b19-6eac-4e3d-96bb-b4077328c378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.84.0)\n",
            "Collecting google-api-python-client\n",
            "  Downloading google_api_python_client-2.107.0-py2.py3-none-any.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httplib2<1.dev0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.61.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.7.22)\n",
            "Installing collected packages: tzdata, pandas, google-api-python-client\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 2.84.0\n",
            "    Uninstalling google-api-python-client-2.84.0:\n",
            "      Successfully uninstalled google-api-python-client-2.84.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-api-python-client-2.107.0 pandas-2.1.2 tzdata-2023.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "api_key = 'AIzaSyCfTwWKjCXEs3lEdvx2GwKHdngxw4IU4-0'  # Replace with your API key\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "search_query = 'Pudgy Penguins'\n",
        "max_results = 100000  # Maximum number of results to retrieve\n",
        "\n",
        "search_response = youtube.search().list(\n",
        "   q=search_query,\n",
        "   type='video',\n",
        "   part='id',\n",
        "   maxResults=max_results\n",
        ").execute()\n",
        "\n",
        "video_list = search_response.get('items', [])\n",
        "\n",
        "# Create lists to store data\n",
        "video_data = []\n",
        "\n",
        "for video in video_list:\n",
        "   video_id = video['id']['videoId']\n",
        "   video_response = youtube.videos().list(\n",
        "       id=video_id,\n",
        "       part='snippet,statistics',\n",
        "   ).execute()\n",
        "\n",
        "   video_info = video_response.get('items', [])[0]\n",
        "   author = video_info['snippet']['channelTitle']\n",
        "   title = video_info['snippet']['title']\n",
        "   description = video_info['snippet']['description']\n",
        "   views = video_info['statistics']['viewCount']\n",
        "   likes = video_info['statistics'].get('likeCount', 0)\n",
        "   dislikes = video_info['statistics'].get('dislikeCount', 0)\n",
        "   upload_date = video_info['snippet']['publishedAt']\n",
        "\n",
        "   # Fetch comments for the video (handle commentsDisabled)\n",
        "   comments = []\n",
        "   try:\n",
        "       comments_response = youtube.commentThreads().list(\n",
        "           videoId=video_id,\n",
        "           textFormat='plainText',\n",
        "           part='snippet',\n",
        "           maxResults=100  # Adjust as needed\n",
        "       ).execute()\n",
        "\n",
        "       comments = [comment['snippet']['topLevelComment']['snippet']['textDisplay'] for comment in comments_response.get('items', [])]\n",
        "   except Exception as e:\n",
        "       # Handle the case where comments are disabled or an error occurs\n",
        "       comments = [\"Comments are disabled or an error occurred\"]\n",
        "\n",
        "   video_data.append([video_id, title, description, author, views, likes, dislikes, upload_date, comments])\n",
        "\n",
        "# Convert data to a DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "columns = ['Video ID', 'Title', 'Description', 'Author', 'Views', 'Likes', 'Dislikes', 'Upload Date', 'Comments']\n",
        "df = pd.DataFrame(video_data, columns=columns)\n",
        "\n",
        "df = df.explode('Comments')\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "# Save the data to a CSV file\n",
        "df.to_csv('youtube_data.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "from google.colab import files\n",
        "files.download('youtube_data.csv')\n"
      ],
      "metadata": {
        "id": "0IYHp9KkJNBh",
        "outputId": "d58ce9ae-9549-4054-f8cc-f324f4813f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4dc27c19-1843-4f74-9136-37977785a7b9\", \"youtube_data.csv\", 475916)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "api_key = 'AIzaSyCfTwWKjCXEs3lEdvx2GwKHdngxw4IU4-0'  # Replace with your API key\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "search_query = 'Luca Netz'\n",
        "max_results = 50  # Maximum number of results to retrieve\n",
        "\n",
        "search_response = youtube.search().list(\n",
        "   q=search_query,\n",
        "   type='video',\n",
        "   part='id',\n",
        "   maxResults=max_results\n",
        ").execute()\n",
        "\n",
        "video_list = search_response.get('items', [])\n",
        "\n",
        "# Create lists to store data\n",
        "video_data = []\n",
        "\n",
        "for video in video_list:\n",
        "   video_id = video['id']['videoId']\n",
        "   video_response = youtube.videos().list(\n",
        "       id=video_id,\n",
        "       part='snippet,statistics',\n",
        "   ).execute()\n",
        "\n",
        "   video_info = video_response.get('items', [])[0]\n",
        "   author = video_info['snippet']['channelTitle']\n",
        "   title = video_info['snippet']['title']\n",
        "   description = video_info['snippet']['description']\n",
        "   views = video_info['statistics']['viewCount']\n",
        "   likes = video_info['statistics'].get('likeCount', 0)\n",
        "   dislikes = video_info['statistics'].get('dislikeCount', 0)\n",
        "   upload_date = video_info['snippet']['publishedAt']\n",
        "\n",
        "   # Fetch comments for the video (handle commentsDisabled)\n",
        "   comments = []\n",
        "   try:\n",
        "       comments_response = youtube.commentThreads().list(\n",
        "           videoId=video_id,\n",
        "           textFormat='plainText',\n",
        "           part='snippet',\n",
        "           maxResults=100  # Adjust as needed\n",
        "       ).execute()\n",
        "\n",
        "       comments = [comment['snippet']['topLevelComment']['snippet']['textDisplay'] for comment in comments_response.get('items', [])]\n",
        "   except Exception as e:\n",
        "       # Handle the case where comments are disabled or an error occurs\n",
        "       comments = [\"Comments are disabled or an error occurred\"]\n",
        "\n",
        "   video_data.append([video_id, title, description, author, views, likes, dislikes, upload_date, comments])\n",
        "\n",
        "# Convert data to a DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "columns = ['Video ID', 'Title', 'Description', 'Author', 'Views', 'Likes', 'Dislikes', 'Upload Date', 'Comments']\n",
        "df = pd.DataFrame(video_data, columns=columns)\n",
        "\n",
        "# Save the data to a CSV file\n",
        "df.to_csv('youtube_data.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "from google.colab import files\n",
        "files.download('youtube_data.csv')"
      ],
      "metadata": {
        "id": "2YWG2SbX-tAt",
        "outputId": "358e598a-ef27-4a5b-9c75-ef5f45e7ea48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1a9196c5-d859-4e41-8924-e17a2838d965\", \"youtube_data.csv\", 97857)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules and authenticate with your API key.\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'YOUR_API_KEY' with your actual API key.\n",
        "api_key = 'AIzaSyCfTwWKjCXEs3lEdvx2GwKHdngxw4IU4-0'\n",
        "\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "# Define your search query.\n",
        "search_query = 'Pudgy Penguins'\n",
        "\n",
        "# Create a list to store all video data.\n",
        "all_video_data = []\n",
        "\n",
        "next_page_token = None\n",
        "\n",
        "while True:\n",
        "    # Execute the search request with a page token.\n",
        "    search_response = youtube.search().list(\n",
        "        q=search_query,\n",
        "        type='video',\n",
        "        part='id',\n",
        "        maxResults=50,  # Adjust this based on your needs, but 50 is the maximum per page.\n",
        "        pageToken=next_page_token\n",
        "    ).execute()\n",
        "\n",
        "    video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]\n",
        "\n",
        "    if not video_ids:\n",
        "        break\n",
        "\n",
        "    # Loop through the video IDs and retrieve video data.\n",
        "    for video_id in video_ids:\n",
        "        # Retrieve video metadata.\n",
        "        video_response = youtube.videos().list(\n",
        "            part='snippet,statistics',\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "\n",
        "        video_data = video_response['items'][0]['snippet']\n",
        "        video_stats = video_response['items'][0]['statistics']\n",
        "\n",
        "        all_video_data.append([\n",
        "            video_id,\n",
        "            video_data['title'],\n",
        "            video_data['description'],\n",
        "            video_data['channelTitle'],\n",
        "            video_stats.get('viewCount', 0),\n",
        "            video_stats.get('likeCount', 0),\n",
        "            video_stats.get('dislikeCount', 0),\n",
        "            video_data['publishedAt'],\n",
        "            video_stats.get('commentCount', 0)\n",
        "        ])\n",
        "\n",
        "    # Check if there are more pages of results.\n",
        "    next_page_token = search_response.get('nextPageToken')\n",
        "\n",
        "    if not next_page_token:\n",
        "        break\n",
        "\n",
        "# Create a DataFrame to store the video data.\n",
        "df = pd.DataFrame(all_video_data, columns=[\n",
        "    'Video ID', 'Title', 'Description', 'Author', 'Views', 'Likes', 'Dislikes', 'Upload Date', 'Comment Count'\n",
        "])\n",
        "\n",
        "# Save the data to a CSV file.\n",
        "csv_file_name = 'youtube_data.csv'\n",
        "df.to_csv(csv_file_name, index=False)\n",
        "\n",
        "# Verify and download the CSV file.\n",
        "import shutil\n",
        "shutil.move(csv_file_name, \"/content/\" + csv_file_name)\n",
        "\n",
        "import os\n",
        "os.listdir(\"/content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQHu0xRWhE9H",
        "outputId": "928706cb-0ba1-4c9c-a986-83ca76917012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'youtube_data.csv', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules and authenticate with your API key.\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'YOUR_API_KEY' with your actual API key.\n",
        "api_key = 'AIzaSyCfTwWKjCXEs3lEdvx2GwKHdngxw4IU4-0'\n",
        "\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "# Define your search query.\n",
        "search_query = 'Pudgy Penguins'\n",
        "\n",
        "# Create a list to store all video data.\n",
        "all_video_data = []\n",
        "\n",
        "next_page_token = None\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Execute the search request with a page token and set the relevanceLanguage parameter to 'en'.\n",
        "    search_response = youtube.search().list(\n",
        "        q=search_query,\n",
        "        type='video',\n",
        "        part='id',\n",
        "        maxResults=50,  # Adjust this based on your needs, but 50 is the maximum per page.\n",
        "        pageToken=next_page_token,\n",
        "        relevanceLanguage='en'  # Add this parameter to filter by English language content.\n",
        "    ).execute()\n",
        "\n",
        "    video_ids = [item['id']['videoId'] for item in search_response.get('items', [])]\n",
        "\n",
        "    if not video_ids:\n",
        "        break\n",
        "\n",
        "    # Loop through the video IDs and retrieve video data.\n",
        "    for video_id in video_ids:\n",
        "        # Retrieve video metadata.\n",
        "        video_response = youtube.videos().list(\n",
        "            part='snippet,statistics',\n",
        "            id=video_id\n",
        "        ).execute()\n",
        "\n",
        "        video_data = video_response['items'][0]['snippet']\n",
        "        video_stats = video_response['items'][0]['statistics']\n",
        "\n",
        "        # Fetch comments for the video (handle commentsDisabled)\n",
        "        comments = []\n",
        "        try:\n",
        "            comments_response = youtube.commentThreads().list(\n",
        "                videoId=video_id,\n",
        "                textFormat='plainText',\n",
        "                part='snippet',\n",
        "                maxResults=100  # Adjust as needed\n",
        "            ).execute()\n",
        "\n",
        "            comments = [comment['snippet']['topLevelComment']['snippet']['textDisplay'] for comment in comments_response.get('items', [])]\n",
        "        except Exception as e:\n",
        "            # Handle the case where comments are disabled or an error occurs\n",
        "            comments = [\"Comments are disabled or an error occurred\"]\n",
        "\n",
        "        all_video_data.append([\n",
        "            video_id,\n",
        "            video_data['title'],\n",
        "            video_data['description'],\n",
        "            video_data['channelTitle'],\n",
        "            video_stats.get('viewCount', 0),\n",
        "            video_stats.get('likeCount', 0),\n",
        "            video_stats.get('dislikeCount', 0),\n",
        "            video_data['publishedAt'],\n",
        "            video_stats.get('commentCount', 0),\n",
        "            comments\n",
        "        ])\n",
        "\n",
        "    # Check if there are more pages of results.\n",
        "    next_page_token = search_response.get('nextPageToken')\n",
        "\n",
        "    if not next_page_token:\n",
        "        break\n",
        "\n",
        "# Create a DataFrame to store the video data.\n",
        "df = pd.DataFrame(all_video_data, columns=[\n",
        "    'Video ID', 'Title', 'Description', 'Author', 'Views', 'Likes', 'Dislikes', 'Upload Date', 'Comment Count','Comments'\n",
        "])\n",
        "\n",
        "# Save the data to a CSV file.\n",
        "csv_file_name = 'youtube_data(new).csv'\n",
        "\n",
        "df = df.explode('Comments')\n",
        "\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "df.to_csv(csv_file_name, index=False)\n",
        "\n",
        "# Verify and download the CSV file.\n",
        "import shutil\n",
        "shutil.move(csv_file_name, \"/content/\" + csv_file_name)\n",
        "\n",
        "import os\n",
        "os.listdir(\"/content\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lnviMooLngD",
        "outputId": "0a5df19e-f2a3-4ed7-e3c6-843bb672a52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n",
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"commentsDisabled\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'youtube_data(new).csv', 'youtube_data.csv', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}